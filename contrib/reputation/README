INTRODUCTION

This area contains a snapshot of the ongoing development of a rudimentary
reputation system based on OpenDKIM's statistics package.

The statistics package is able to capture the flow of mail arriving as it
passes through OpenDKIM.  All messages, even unsigned ones, are recorded.
For signed messages, all signatures are recorded including pass/fail,
signing domain, signature properties, etc.  The statistics system can also
upload the locally-collected data to an arbitrary central repository where
it can be aggregated and then made available to participants to query.

This central system has not yet been designed to be queryable as a public
service, but may be in the future.  This directory contains a description
sufficient to build such a system, but also (and primarily) for building a
local store that can be used as an intelligent filter based on DKIM
verification results.

REQUIREMENTS

The requirements for this reputation system are as follows:

1) Reputation must be based on the domain(s) that have some kind of
   responsibility for the message.

2) Reputation should be expressed in such a way that it can be easily
   converted to a message flow limit.

3) There must be some reasonable, even if tiny, allowance made for
   domains about which no data have been accumulated.

4) The system may output a few values for a given domain, such as
   "strict", "medium" and "light", and these would be applied at the
   discretion of the implementation.

5) Data expiration must be configurable at the discretion of the site using
   the system.  That is, the system should neither impose a specific lifetime
   of the data accumulated, though it should discuss the impacts of different
   choices of data lifetime.


OVERVIEW

The system computes a recommended flow based on the history of the
behaviour of the signing domain(s) on a message.  Mail that is unsigned will
be treated as though it was signed by the NULL domain, meaning all unsigned
mail is presumed to come from a common source ("the unknown", as it were).
What remains, then, is to determine the perceived value of mail from each
of these sources.  This is done via data collection and statistical methods.

What is critical, then, is a comparison of two things for any given source:

(a) How much mail that source sends in a given time period; and

(b) How much of that mail is undesired (spam, phish, virus, etc.).

The first part is the easy part.  In our case, this is done via the
opendkim filter (which extracts DKIM results) and an SQL data store
(which records these results).  This sort of data allows one to construct
a view of the past behaviour of a domain in terms of sending volume only.
Various mechanisms exist such as predictive inference and time series
analysis to determine what might be expected for the next time period.
For our first implementation, we use predictive inference as it is simpler
to calculate.

The second part is the hard part.  Identifying spam in an accurate and timely
manner is the key to building effective filtering systems.  Commercial
solutions such as Cloudmark's SpamNet are highly effective specifically
because they base their accuracy not only on clever algorithms that extract
interesting properties, but also on the feedback of their users to tell
them which of those properties are typically associated with a spam message.
This also gives rise to trust in the reporters, where more value is given
to feedback from a reporter that is usually quick to report and concurs
with the majority.  However, a universal feedback system in the open source
world does not yet exist.  Thus, for this experiment, we provide some local
tools for administrators to make available to users, but primarily focus
on the use of SpamAssassin as a fast and reasonably accurate feedback system.

This means, for each arriving message, we have a set of one or more valid
DKIM signatures, and an indication of whether or not the message is
considered spam.

For the purposes of illustration of this method, we will use the counts from
a single calendar day (i.e., midnight to midnight) as a data point.

The next section describes the reputation system in detail, and the following
one explains how to configure and activate it.


DESIGN DETAILS

For each message collected by the statistics system, numerous details are
recorded.  For the full schema, see stats/mkdb.mysql and stats/README.

Let each message M have associated with it the set D of domains for which
valid signatures were present upon receipt.  D may be empty, in which case
we pretend there was one valid signature for the domain NULL.  Each M also
has a value S associated with it, which is either 0 if the message was not
labeled as spam or 1 if it is.

Thus, within a given day, any domain has a count Cm of messages that had
a valid signature on it from that domain, and a count Cs of messages that
were spam.  Obviously, for any given day, Cm >= Cs.  And over N days,
any given domain will have N of each of these.  Considering the data for
any given domain, this permits some useful analysis.

Trivially, one can compute the average daily number of messages bearing a
valid signature from any given domain, and the average number of those that
are spam.  It would then be easy to detect when the amount of spam, or the
amount of mail in general, went above average at all, or perhaps by a certain
percentage.  The simple mean, however, is too volatile for these purposes.
Something more robust (i.e., less influenced by extreme data points) is
required.

Were we to plot such data on a graph using the message count on the X axis
and the spam count on the Y axis, we could approximate the data set with a
line using some method of regression.  If the slope of that line approaches
1, then the domain tends to send spam; if it approaches zero, it tends to be
a clean source of mail.  Using this method might also be helpful to predict
a value of Cs for a new day given a value for Cm for that day.  However,
linear regression methods presuppose minimal error in measurement, and although
we are sure of our received message count, the spam count is subjective
because SpamAssassin is not as precise as we would like for this work.

This experiment instead uses predictive inference as its method of computing
results.  A prediction interval is based on the mean and standard deviation
of a data set and is used to estimate, given a set of previous values, a
range in which the next value will fall.  A typical prediction interval
for a data set, given those two values is defined by:

	[ u - o z, u + o z ]

...where:

	u ("mu") is the sample mean from the data observed to date
	o ("sigma") is the standard deviation from the data observed to date
	z ("zeta") is the standard score for the size of the prediction
	  interval desired

The experiment uses the assumption that the distribution of the data
points for any given domain is normal; that is, that the data points for
any given domain tend to cluster around a single mean value.

The prediction interval is centered around the mean, and its width is
governed by the width of the standard score and the standard deviation.

The standard score governs the width of the prediction interval.  A
prediction interval's description is what provides the "z" value above, but
not in an intuitive way: A 90% prediction interval is 90% likely to contain
the next data point, but is possibly considerably wider than a 75%
prediction interval based on the same data (so that it is 90% likely to be
right).  Thus, a less precise (tighter) interval may lead to some false
alarms, but a more precise (wider) interval may lead to no intervention at
all.  In this implementation, we leave the choice of the interval
width to the administrator of the system being protected.

The standard deviation is a measure of how erratic the behaviour of the
measured quantity is.

We introduce one additional quantity here: R, which is Cs/Cm for a given
day for a given domain; it is the ratio of spam to messages, or the percent
of mail that is spam for a given day from a given domain.

In general, we construct a prediction interval around the Cm and R data
for any given domain based on observed data to date.  This gives a low
and high end of a range within which the next daily message count and daily
spam ratio are expected to fall.

Note that we are not always interested in the lower boundary of the prediction
interval as there's no action to be taken should a daily message count or
daily spam count fall below normal (less mail and/or less spam aren't
things that require intervention), but this point will be revisited later.

Thus, at the start of day X, we compute a prediction interval for all domains
for which we have accumulated data (including the NULL domain) for the
message count and the spam ratio.  If during day X we observe that the domain
has sent more than the predicted high or the ratio of received mail to spam
exceeds the high prediction, intervention can be enacted.

This seems to be a good fit on simple analysis: If a domain sends the same
amount of mail every day, then the mean will be that value, the standard
deviation will be zero, and thus the prediction will be that same value.
As the value varies, the standard deviation increases, and this variability
grants some tolerance in the prediction interval for increases in traffic
that might not be present using a simpler model.  For the spam ratio, the
mean gives an indication of how clean the domain's stream is, and the
standard deviation a measure of how erratic the domain's behaviour typically
is.  This can be used as a measure of the trustworthiness of the stream
in terms of sending desirable content.  In fact, one could conceive of
a system that uses the low, middle (mean) and high points in the ratio's
prediction interval to impose light, moderate and aggressive rate limiting
modes against senders.  We can call these Plow, Pmed, Phigh; the one a site
chooses to use is simply called P.

A simpler model combining these is possible: On day X, allow through a
quantity of mail from a domain equal to the high end of its prediction
interval on Cm multiplied by the quantity (1 - P).  Where the standard
deviation around R is larger than the mean, this quantity can be negative;
in that case, we simply use a value of zero, effectively cutting that domain
off; it has earned itself a ban.

Note, though, that these statistical quantities are only really useful
once a substantial number of data points exist.  It's necessary then to
create a second system for handling domains about which there is little
information available.  This is a particularly sensitive point given the
fact that many domains are created solely to send a spam campaign and are
then abandoned, and many of these sign their mail.

Thus, the system as a whole divides domains into two categories: high-data
and low-data.  An obvious question, then, is what a good threshold is at
which a domain transitions from one to the other.  So we have two problems
to solve.

First, we need a method to determine that threshold.  In a simple system,
a fixed time limit could be imposed, i.e. a domain transitions from
low-data to high-data after having some predetermined number of days of
activity recorded.  We would like to do something a little more automated.
For now we will use the fixed time limit and return to this question later.

If the current day is X(0), let N be the fixed time threshold in days.
Thus the low-time threshold is at day X(N).  Compute the mean and standard
deviation for the Cm and R values across all signing domains for data from
X(1) to X(N).  This gives us the ability to construct a prediction interval
for those values in the aggregate across all low-time domains.  This quantity
is thus a measure of how we expect new domains to behave given the observed
behaviour of other new domains.  Therefore, we enforce the prediction
interval of Cm on low-time domains, modulated by R as above.  As a tiny
measure of "benefit of the doubt", a flow limit computed in this way to be
zero is modulated further to permit some small (perhaps fixed, perhaps based
on a ratio) quantity of mail until a single spam message is detected, at
which point no further mail is allowed that day.

Now we revisit the question of what N should be.  The statistics package
can be used to determine the first and last time a domain name was seen
used in a signature.  So for each domain name we also compute L, the
difference in days between "first seen" and "last seen".  This gives us yet
another data set upon which to compute a mean and standard deviation.
If we constrain this to include only L values for domains that send mostly
spam, we can see how long a spam-generating domain tends to live before
being abandoned for attracting attention.  For the deployed test system,
we set N using a simple value of twice the average of L; the standard
deviation in this case is ignored.  An alternate approach is to compute a
prediction interval around the mean L value; the high end value becomes
the value used for N.

Next we need to design the system so that messages that are disallowed
because of the above rate controls are still counted in that domain's
aggregated data.  A "temporary failure" result returned in that case may
cause a re-send attempt; this is not to be counted as a separate message
in order to get a real view of what that domain attempted to send.

We finally need to define an initial state, where the system doesn't know
anything.  For simplicity, we will run the system in wide-open data
collection only mode for 30 days prior to doing any rate throttling.


SUMMARY

Given a set of numbers, one can compute the well-known statistical
quantities know as the mean (the average value of the set) and standard
deviation (a measure of the dispersal of values about the mean) as useful
tools to describe the set.

Select a prediction interval width to be used for the system (e.g.,
75%, 90%, or 95%).  Using a lookup table, this gives the standard score, "z",
to be used at various points in this algorithm.

Select a ratio that indicates a relatively unknown domain that sends more
than that ratio of spam is considered undesirable.  Call this S.

Select Mmin, a minimum number of messages to allow in per day from an unknown
source regardless of calculated limits.

Select a strictness setting, "light", "medium" or "strict".

Let D be a set of domain names.  It is further partitioned into Dlow and
Dhigh, these being, respectively, domains about which we have only a small
amount of data and those about which we have accumulated a useful amount
of data.

For each M received, record the following details:

	- the set of domain names taken from valid DKIM signatures, if any
	- the time at which the message was received
	- a Boolean indication of whether or not the message was spam

Partition these records into "buckets", one per day.  We can now compute
the following quantities about any given domain or about the system as a
whole, and across all observed days or for any given day

	- total messages sent (Cm)
	- total spam sent (Cs)
	- count of days for which data are available

For each domain D, compute the following quantities:

	- mean messages sent (uCm)
	- mean spam messages sent (uCs)
	- mean spam ratio (uR = uCs / uCm)
	- the time, in days, between this domain's first use in a valid
	  signature and its last use in a valid signature (L)

Discard those for which uR is less than S or uCm is less than 2.

Compute the mean and standard deviation for L, and then a prediction interval
around uL.  Denote the high end of this prediction interval to be N.
Partition the set of known domains D into Dlow and Dhigh based on whether
or not L for a given domain is above or below this value.

Compute a prediction interval around uCm and uR for all domains in Dlow.
Denote the high end of the prediction interval around uCm as Chigh, and
the high end of the prediction interval around uR as Rhigh.  Impose a
per-domain overall message rate on domains in Dlow defined by:

	M = Chigh * (1 - Rhigh)

Furthermore ensure that a given domain does not exceed a daily spam ratio R
selected based on the strictness setting: use Rlow for "light", uR for
"medium", or Rhigh for "strict".

This allows messages to be sent by a low time domain up to what it might
legitimately send regardless of content, modulated downward by the average
low time domain's expected behaviour.  If most low time domains send
undesirable mail, this number will approach zero or even be negative.
If that's the case, the hard-coded minimum rate Mmin is used, except that
no further mail is accepted once a single piece of spam is observed.

Next, compute a prediction interval around uCm and uR for each domain in
Dhigh.  Denote the high end of the prediction interval around a domain's Cm
as Chigh, and the high end of the prediction interval around R as Rhigh.
Impose a per-domain overall message rate on domains in Dhigh defined by:

	M = Chigh * (1 - Rhigh)

Similarly restrict the spam ratio for each high-time domani according
to Rlow, uR or Rhigh as described above.

This allows messages to be sent by a high time domain up to what it might
legitimately send regardless of content, modulated downward by that domain's
expected behaviour.  Unlike for the low time domains, this is not dependent
on the behaviour of other domains.  A domain that earns a high enough value
of Rhigh can cause its daily limit to be modulated down to zero.


DISCUSSION

The standard deviation in the computation of Rhigh acts as a measure of
trust in the domain's behaviour; the more erratic its spam behaviour is,
the higher the standard deviation becomes, the larger the value of Rhigh
gets, and the more Chigh is penalized.

The more well-behaved a domain is, the more leeway it is given.  It is
presumed that any domain will have some variability in its Cm values, meaning
it will have a standard deviation around C, meaning Chigh will be bigger
than average.  A well-behaved (low Rhigh) domain, then, will implicitly give
the domain room to "grow" as it continues to behave well.

A domain that is well-behaved for a long period will have relatively low
values for Rlow, uR and Rhigh.  Thus, since both an overall message rate
and a spam rate are enforced, a sudden surge in spam from a typically
well-behaved domain will be intercepted by the enforcement of the R-limits
even if there's lots of room left in a given day to play with the M limit.

This system obviously creates a long-term incentive for a particular signing
domain to behave well and do so consistently.


EXPERIMENTAL DATA

